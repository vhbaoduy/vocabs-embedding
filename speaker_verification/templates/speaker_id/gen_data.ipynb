{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Format data from word/speaker to speaker/word\n",
    "# import os\n",
    "# import re\n",
    "# import shutil\n",
    "# src_data_path=\"D:/tensorflow-speech-recognition-challenge/train/audio\"\n",
    "# dest_data_path=\"D:/tensorflow-speech-recognition-challenge/out\"\n",
    "# list_speaker_path=\"D:/tensorflow-speech-recognition-challenge/train/testing_list.txt\"\n",
    "# speakers =  []\n",
    "# words = []\n",
    "# # f = open(list_speaker_path)\n",
    "# # lines = f.readlines()\n",
    "# # pat_speaker= r'.*?\\/(.*)_.*'\n",
    "\n",
    "# # for line in lines:\n",
    "# #     match = re.search(pat_speaker, line.strip())\n",
    "# #     speakers.append(match.group(1).replace(\"_nohash\",\"\"))\n",
    "\n",
    "# for word in os.listdir(src_data_path):\n",
    "#     if word != \"_background_noise_\":\n",
    "#         for audio in os.listdir(src_data_path+\"/\"+word):\n",
    "#             speakers.append(audio.split('_')[0]) \n",
    "# speakers = list(dict.fromkeys(speakers))\n",
    "\n",
    "# for speaker in speakers:\n",
    "#     if not os.path.exists(dest_data_path+'/'+speaker):\n",
    "#         os.makedirs(dest_data_path+'/'+speaker)\n",
    "\n",
    "# for word in os.listdir(src_data_path):\n",
    "#     if word != \"_background_noise_\":\n",
    "#         words.append(word)\n",
    "#         for audio in os.listdir(src_data_path+\"/\"+word):\n",
    "#             speaker = audio.split('_')[0]\n",
    "#             if os.path.exists(dest_data_path+'/'+speaker):\n",
    "#                 shutil.copyfile(src_data_path+\"/\"+word+\"/\"+audio, dest_data_path+\"/\"+speaker+\"/\"+word+audio.replace(speaker,\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 2 word\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import wave\n",
    "src_path = \"D:/tensorflow-speech-recognition-challenge/out/\"\n",
    "dest_path = \"D:/tensorflow-speech-recognition-challenge/out_balance/\"\n",
    "words = ['three', 'down']\n",
    "for speaker in os.listdir(src_path):\n",
    "    count_1 = 0\n",
    "    count_2 = 0 \n",
    "    for file in os.listdir(os.path.join(src_path,speaker)):\n",
    "        if file.startswith(words[0]):\n",
    "            count_1 +=1\n",
    "        if file.startswith(words[1]):\n",
    "            count_2 += 1\n",
    "    if count_1 >= 3 and count_2 >= 3:\n",
    "        print(speaker)\n",
    "        if not os.path.exists(os.path.join(dest_path,speaker)):\n",
    "            os.makedirs(os.path.join(dest_path,speaker))\n",
    "        count=list()\n",
    "        count.append(count_1)\n",
    "        count.append(count_2)\n",
    "        \n",
    "        for c1 in range(count[0]):\n",
    "            for c2 in range(count[1]):\n",
    "                data = []\n",
    "                outfile = dest_path+speaker+\"/\"+speaker+\"_\"+words[0]+\"_\"+words[1]+\"_\"+str((c1*count[1])+c2)+\".wav\"\n",
    "                \n",
    "                if not os.path.exists(src_path+speaker+\"/\"+words[0]+\"__nohash_\"+str(c1)+\".wav\") or not os.path.exists(src_path+speaker+\"/\"+words[1]+\"__nohash_\"+str(c2)+\".wav\"):\n",
    "                    continue\n",
    "                \n",
    "                w = wave.open(src_path+speaker+\"/\"+words[0]+\"__nohash_\"+str(c1)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())])\n",
    "                w.close()\n",
    "\n",
    "                w = wave.open(src_path+speaker+\"/\"+words[1]+\"__nohash_\"+str(c2)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())] )\n",
    "                w.close()\n",
    "                    \n",
    "                output = wave.open(outfile, 'wb')\n",
    "                output.setparams(data[0][0])\n",
    "                for i in range(len(data)):\n",
    "                    output.writeframes(data[i][1])\n",
    "                output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "016e2c6d\n",
      "1626bc5a\n",
      "17f0e206\n",
      "1df483c0\n",
      "2151b09a\n",
      "377e916b\n",
      "4845bb10\n",
      "4c77947d\n",
      "4f2ab70c\n",
      "529eda42\n",
      "571c044e\n",
      "6c6aa323\n",
      "6cf5459b\n",
      "7e6bd776\n",
      "80c45ed6\n",
      "9080f6d3\n",
      "977a3be4\n",
      "9a7c1f83\n",
      "9efe5140\n",
      "9f7079fe\n",
      "a8f45bdc\n",
      "b19f7f5f\n",
      "b4bef564\n",
      "b59fe16d\n",
      "c0e0f834\n",
      "c120e80e\n",
      "c1d39ce8\n",
      "c7b4049e\n",
      "de4f7798\n",
      "ec7d1151\n",
      "f816db77\n",
      "fd32732a\n",
      "fde2dee7\n"
     ]
    }
   ],
   "source": [
    "# Combine 2 sound, rule: speaker contains 2 pharse\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import wave\n",
    "src_path = \"D:/tensorflow-speech-recognition-challenge/out/\"\n",
    "dest_path = \"D:/tensorflow-speech-recognition-challenge/out_balance_1/\"\n",
    "dest_path_1 = \"D:/tensorflow-speech-recognition-challenge/out_balance_2/\"\n",
    "const_count = 2\n",
    "words = ['three', 'down', 'three', 'tree']\n",
    "for speaker in os.listdir(src_path):\n",
    "    count_1 = 0\n",
    "    count_2 = 0 \n",
    "    \n",
    "    count_3 = 0\n",
    "    count_4 = 0\n",
    "\n",
    "    for file in os.listdir(os.path.join(src_path,speaker)):\n",
    "        if file.startswith(words[0]):\n",
    "            count_1 +=1\n",
    "        if file.startswith(words[1]):\n",
    "            count_2 += 1\n",
    "\n",
    "    for file in os.listdir(os.path.join(src_path,speaker)):\n",
    "        if file.startswith(words[2]):\n",
    "            count_3 +=1\n",
    "        if file.startswith(words[3]):\n",
    "            count_4 += 1\n",
    "\n",
    "    # Pharse 1\n",
    "    if count_1 >= 2 and count_2 >= 2 and count_3 >= 2 and count_4 >= 2:\n",
    "        print(speaker)\n",
    "        if not os.path.exists(os.path.join(dest_path,speaker)):\n",
    "            os.makedirs(os.path.join(dest_path,speaker))\n",
    "        count=list()\n",
    "        count.append(count_1)\n",
    "        count.append(count_2)\n",
    "        \n",
    "        for c1 in range(const_count):\n",
    "            for c2 in range(const_count):\n",
    "                data = []\n",
    "                outfile = dest_path+speaker+\"/\"+speaker+\"_\"+words[0]+\"_\"+words[1]+\"_\"+str((c1*const_count)+c2)+\".wav\"\n",
    "                \n",
    "                if not os.path.exists(src_path+speaker+\"/\"+words[0]+\"__nohash_\"+str(c1)+\".wav\") or not os.path.exists(src_path+speaker+\"/\"+words[1]+\"__nohash_\"+str(c2)+\".wav\"):\n",
    "                    continue\n",
    "                \n",
    "                w = wave.open(src_path+speaker+\"/\"+words[0]+\"__nohash_\"+str(c1)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())])\n",
    "                w.close()\n",
    "\n",
    "                w = wave.open(src_path+speaker+\"/\"+words[1]+\"__nohash_\"+str(c2)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())] )\n",
    "                w.close()\n",
    "                    \n",
    "                output = wave.open(outfile, 'wb')\n",
    "                output.setparams(data[0][0])\n",
    "                for i in range(len(data)):\n",
    "                    output.writeframes(data[i][1])\n",
    "                output.close()\n",
    "    \n",
    "    # Pharse 2\n",
    "    if count_1 >= 2 and count_2 >= 2 and count_3 >= 2 and count_4 >= 2:\n",
    "        # print(speaker)\n",
    "        if not os.path.exists(os.path.join(dest_path_1,speaker)):\n",
    "            os.makedirs(os.path.join(dest_path_1,speaker))\n",
    "        count=list()\n",
    "        count.append(count_3)\n",
    "        count.append(count_4)\n",
    "        \n",
    "        for c1 in range(const_count):\n",
    "            for c2 in range(const_count):\n",
    "                data = []\n",
    "                outfile = dest_path_1+speaker+\"/\"+speaker+\"_\"+words[2]+\"_\"+words[3]+\"_\"+str((c1*const_count)+c2)+\".wav\"\n",
    "                \n",
    "                if not os.path.exists(src_path+speaker+\"/\"+words[2]+\"__nohash_\"+str(c1)+\".wav\") or not os.path.exists(src_path+speaker+\"/\"+words[3]+\"__nohash_\"+str(c2)+\".wav\"):\n",
    "                    continue\n",
    "                \n",
    "                w = wave.open(src_path+speaker+\"/\"+words[2]+\"__nohash_\"+str(c1)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())])\n",
    "                w.close()\n",
    "\n",
    "                w = wave.open(src_path+speaker+\"/\"+words[3]+\"__nohash_\"+str(c2)+\".wav\", 'rb')\n",
    "                data.append( [w.getparams(), w.readframes(w.getnframes())] )\n",
    "                w.close()\n",
    "                    \n",
    "                output = wave.open(outfile, 'wb')\n",
    "                output.setparams(data[0][0])\n",
    "                for i in range(len(data)):\n",
    "                    output.writeframes(data[i][1])\n",
    "                output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wave\n",
    "# import shutil\n",
    "\n",
    "# src_path = \"D:/tensorflow-speech-recognition-challenge/out_combine\"\n",
    "# dest_path = \"D:/tensorflow-speech-recognition-challenge/out_data\"\n",
    "# limit_speaker = 300\n",
    "# count = 0\n",
    "\n",
    "# # words = [\"bird_cat\",\"bird_dog\",\"bird_down\",\"cat_dog\",\"cat_house\",\"cat_two\",\"cat_up\"]\n",
    "# words = ['bird_cat.wav', 'bird_dog.wav', 'bird_down.wav', 'bird_eight.wav', 'bird_five.wav', 'bird_go.wav', 'bird_house.wav', 'bird_left.wav', 'bird_marvin.wav', 'bird_nine.wav', 'bird_off.wav', 'bird_on.wav', 'bird_right.wav', 'bird_six.wav', 'bird_three.wav']\n",
    "\n",
    "# for word in words:\n",
    "#     count = 0\n",
    "#     for speaker in os.listdir(src_path):\n",
    "#         if os.path.exists(os.path.join(src_path,speaker,word)):\n",
    "#             count+=1\n",
    "#             if not os.path.exists(os.path.join(dest_path,speaker)):\n",
    "#                 os.makedirs(os.path.join(dest_path,speaker))\n",
    "#             shutil.copyfile(os.path.join(src_path,speaker,word), os.path.join(dest_path,speaker,speaker+\"_\"+word))\n",
    "#         if count == limit_speaker:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit speaker\n",
    "path = \"D:/tensorflow-speech-recognition-challenge/out_balance\"\n",
    "for speaker in os.listdir(path):\n",
    "    # print(len(os.listdir(os.path.join(path,speaker))))\n",
    "    if len(os.listdir(os.path.join(path,speaker)))!=25:\n",
    "        shutil.rmtree(os.path.join(path,speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.13 ('speaker_verification')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n speaker_verification ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "root_dir = \"./data\"\n",
    "output_path = \"./output\"\n",
    "labels = ['yes', 'yes']\n",
    "\n",
    "data_preparing = DataPreparing(root_dir, labels, output_path, create_all=False)\n",
    "data_preparing.create_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('speaker_verification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7a604b83fa51294d476ed17812d4a9b08013c95b7490d8ed0ad6eb9ac8d0c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
