{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "src_data_path=\"D:/tensorflow-speech-recognition-challenge/train/audio\"\n",
    "dest_data_path=\"D:/tensorflow-speech-recognition-challenge/out\"\n",
    "list_speaker_path=\"D:/tensorflow-speech-recognition-challenge/train/testing_list.txt\"\n",
    "speakers =  []\n",
    "words = []\n",
    "# f = open(list_speaker_path)\n",
    "# lines = f.readlines()\n",
    "# pat_speaker= r'.*?\\/(.*)_.*'\n",
    "\n",
    "# for line in lines:\n",
    "#     match = re.search(pat_speaker, line.strip())\n",
    "#     speakers.append(match.group(1).replace(\"_nohash\",\"\"))\n",
    "\n",
    "for word in os.listdir(src_data_path):\n",
    "    if word != \"_background_noise_\":\n",
    "        for audio in os.listdir(src_data_path+\"/\"+word):\n",
    "            speakers.append(audio.split('_')[0]) \n",
    "speakers = list(dict.fromkeys(speakers))\n",
    "\n",
    "for speaker in speakers:\n",
    "    if not os.path.exists(dest_data_path+'/'+speaker):\n",
    "        os.makedirs(dest_data_path+'/'+speaker)\n",
    "\n",
    "for word in os.listdir(src_data_path):\n",
    "    if word != \"_background_noise_\":\n",
    "        words.append(word)\n",
    "        for audio in os.listdir(src_data_path+\"/\"+word):\n",
    "            speaker = audio.split('_')[0]\n",
    "            # if os.path.exists(dest_data_path+'/'+speaker):\n",
    "            #     shutil.copyfile(src_data_path+\"/\"+word+\"/\"+audio, dest_data_path+\"/\"+speaker+\"/\"+word+audio.replace(speaker,\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "src_path = \"D:/tensorflow-speech-recognition-challenge/out/\"\n",
    "dest_path = \"D:/tensorflow-speech-recognition-challenge/out_combine/\"\n",
    "\n",
    "for speaker in speakers:\n",
    "    if not os.path.exists(dest_path+speaker):\n",
    "        os.makedirs(dest_path+speaker)\n",
    "\n",
    "for speaker in os.listdir(src_path):\n",
    "    for word_1 in range(len(words)-1):\n",
    "        for word_2 in range(word_1+1,len(words)):\n",
    "            data = []\n",
    "            outfile = dest_path+speaker+\"/\"+words[word_1]+\"_\"+words[word_2]+\".wav\"\n",
    "            \n",
    "            if not os.path.exists(src_path+speaker+\"/\"+words[word_1]+\"__nohash_0.wav\") or not os.path.exists(src_path+speaker+\"/\"+words[word_2]+\"__nohash_0.wav\"):\n",
    "                continue\n",
    "            \n",
    "            w = wave.open(src_path+speaker+\"/\"+words[word_1]+\"__nohash_0.wav\", 'rb')\n",
    "            data.append( [w.getparams(), w.readframes(w.getnframes())])\n",
    "            w.close()\n",
    "\n",
    "            w = wave.open(src_path+speaker+\"/\"+words[word_2]+\"__nohash_0.wav\", 'rb')\n",
    "            data.append( [w.getparams(), w.readframes(w.getnframes())] )\n",
    "            w.close()\n",
    "                \n",
    "            output = wave.open(outfile, 'wb')\n",
    "            output.setparams(data[0][0])\n",
    "            for i in range(len(data)):\n",
    "                output.writeframes(data[i][1])\n",
    "            output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird_cat.wav', 'bird_dog.wav', 'bird_down.wav', 'bird_eight.wav', 'bird_five.wav', 'bird_go.wav', 'bird_house.wav', 'bird_left.wav', 'bird_marvin.wav', 'bird_nine.wav', 'bird_off.wav', 'bird_on.wav', 'bird_right.wav', 'bird_six.wav', 'bird_three.wav', 'bird_tree.wav', 'bird_two.wav', 'bird_up.wav', 'cat_dog.wav', 'cat_down.wav', 'cat_eight.wav', 'cat_five.wav', 'cat_go.wav', 'cat_house.wav', 'cat_left.wav', 'cat_marvin.wav', 'cat_nine.wav', 'cat_off.wav', 'cat_on.wav', 'cat_right.wav', 'cat_six.wav', 'cat_three.wav', 'cat_tree.wav', 'cat_two.wav', 'cat_up.wav', 'dog_down.wav', 'dog_eight.wav', 'dog_five.wav', 'dog_go.wav', 'dog_house.wav', 'dog_left.wav', 'dog_marvin.wav', 'dog_nine.wav', 'dog_off.wav', 'dog_on.wav', 'dog_right.wav', 'dog_six.wav', 'dog_three.wav', 'dog_tree.wav', 'dog_two.wav', 'dog_up.wav', 'down_eight.wav', 'down_five.wav', 'down_go.wav', 'down_house.wav', 'down_left.wav', 'down_marvin.wav', 'down_nine.wav', 'down_off.wav', 'down_on.wav', 'down_right.wav', 'down_six.wav', 'down_three.wav', 'down_tree.wav', 'down_two.wav', 'down_up.wav', 'eight_five.wav', 'eight_go.wav', 'eight_house.wav', 'eight_left.wav', 'eight_marvin.wav', 'eight_nine.wav', 'eight_off.wav', 'eight_on.wav', 'eight_right.wav', 'eight_six.wav', 'eight_three.wav', 'eight_tree.wav', 'eight_two.wav', 'eight_up.wav', 'five_go.wav', 'five_house.wav', 'five_left.wav', 'five_marvin.wav', 'five_nine.wav', 'five_off.wav', 'five_on.wav', 'five_right.wav', 'five_six.wav', 'five_three.wav', 'five_tree.wav', 'five_two.wav', 'five_up.wav', 'go_house.wav', 'go_left.wav', 'go_marvin.wav', 'go_nine.wav', 'go_off.wav', 'go_on.wav', 'go_right.wav', 'go_six.wav', 'go_three.wav', 'go_tree.wav', 'go_two.wav', 'go_up.wav', 'house_left.wav', 'house_marvin.wav', 'house_nine.wav', 'house_off.wav', 'house_on.wav', 'house_right.wav', 'house_six.wav', 'house_three.wav', 'house_tree.wav', 'house_two.wav', 'house_up.wav', 'left_marvin.wav', 'left_nine.wav', 'left_off.wav', 'left_on.wav', 'left_right.wav', 'left_six.wav', 'left_three.wav', 'left_tree.wav', 'left_two.wav', 'left_up.wav', 'marvin_nine.wav', 'marvin_off.wav', 'marvin_on.wav', 'marvin_right.wav', 'marvin_six.wav', 'marvin_three.wav', 'marvin_tree.wav', 'marvin_two.wav', 'marvin_up.wav', 'nine_off.wav', 'nine_on.wav', 'nine_right.wav', 'nine_six.wav', 'nine_three.wav', 'nine_tree.wav', 'nine_two.wav', 'nine_up.wav', 'off_on.wav', 'off_right.wav', 'off_six.wav', 'off_three.wav', 'off_tree.wav', 'off_two.wav', 'off_up.wav', 'on_right.wav', 'on_six.wav', 'on_three.wav', 'on_tree.wav', 'on_two.wav', 'on_up.wav', 'right_six.wav', 'right_three.wav', 'right_tree.wav', 'right_two.wav', 'right_up.wav', 'six_three.wav', 'six_tree.wav', 'six_two.wav', 'six_up.wav', 'three_tree.wav', 'three_two.wav', 'three_up.wav', 'tree_two.wav', 'tree_up.wav', 'two_up.wav']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r\"D:\\tensorflow-speech-recognition-challenge\\out_combine\\00b01445\"))\n",
    "    # print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import shutil\n",
    "\n",
    "src_path = \"D:/tensorflow-speech-recognition-challenge/out_combine\"\n",
    "dest_path = \"D:/tensorflow-speech-recognition-challenge/out_data\"\n",
    "limit_speaker = 300\n",
    "count = 0\n",
    "\n",
    "# words = [\"bird_cat\",\"bird_dog\",\"bird_down\",\"cat_dog\",\"cat_house\",\"cat_two\",\"cat_up\"]\n",
    "words = ['bird_cat.wav', 'bird_dog.wav', 'bird_down.wav', 'bird_eight.wav', 'bird_five.wav', 'bird_go.wav', 'bird_house.wav', 'bird_left.wav', 'bird_marvin.wav', 'bird_nine.wav', 'bird_off.wav', 'bird_on.wav', 'bird_right.wav', 'bird_six.wav', 'bird_three.wav']\n",
    "\n",
    "for word in words:\n",
    "    count = 0\n",
    "    for speaker in os.listdir(src_path):\n",
    "        if os.path.exists(os.path.join(src_path,speaker,word)):\n",
    "            count+=1\n",
    "            if not os.path.exists(os.path.join(dest_path,speaker)):\n",
    "                os.makedirs(os.path.join(dest_path,speaker))\n",
    "            shutil.copyfile(os.path.join(src_path,speaker,word), os.path.join(dest_path,speaker,speaker+\"_\"+word))\n",
    "        if count == limit_speaker:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"D:/tensorflow-speech-recognition-challenge/out_data\"\n",
    "for speaker in os.listdir(path):\n",
    "    if len(os.listdir(os.path.join(path,speaker)))<10:\n",
    "        shutil.rmtree(os.path.join(path,speaker))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c6f8d6a51922308b9349401617bc24ff0fc3dcaa889b7ff03d558d884bdec6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
